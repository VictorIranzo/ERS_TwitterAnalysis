{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import nltk\n",
    "\n",
    "states = [\"ak\",\"al\",\"ar\",\"az\",\"ca\",\"co\",\"ct\",\"de\",\"fl\",\"ga\",\"hi\",\"ia\",\"id\",\"il\",\n",
    "          \"in\",\"ks\",\"ky\",\"la\",\"ma\",\"md\",\"me\",\"mi\",\"mn\",\"mo\",\"ms\",\"mt\",\"nc\",\"nd\",\"ne\",\"nh\",\n",
    "          \"nj\",\"nm\",\"nv\",\"ny\",\"oh\",\"ok\",\"or\",\"pa\",\"ri\",\"sc\",\"sd\",\"tn\",\"tx\",\"ut\",\"va\",\"vt\",\n",
    "          \"wa\",\"wi\",\"wv\",\"wy\"]\n",
    "\n",
    "states_names = {'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "'CT': 'Connecticut', 'DE': 'Delaware', 'DC': 'District of Columbia', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois',\n",
    "'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n",
    "'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC':'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island',\n",
    "'SC': 'South Carolina', 'SD': 'South Dakota', 'TN':'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia',\n",
    "'WA': 'Washington','WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming', 'PR': 'Puerto Rico'}\n",
    "\n",
    "states_codes = {'AL': 1, 'AK': 2, 'AZ': 4, 'AR': 5, 'CA': 6, 'CO': 8,\n",
    "'CT': 9, 'DE': 10, 'DC': 11, 'FL': 12, 'GA': 13, 'HI': 15, 'ID': 16, 'IL': 17,\n",
    "'IN': 18, 'IA': 19, 'KS': 20, 'KY': 21, 'LA': 22, 'ME': 23, 'MD': 24,\n",
    "'MA': 25, 'MI': 26, 'MN': 27, 'MS': 28, 'MO': 29, 'MT': 30,\n",
    "'NE': 31, 'NV': 32, 'NH': 33, 'NJ': 34, 'NM': 35, 'NY': 36, 'NC':37, 'ND': 38, 'OH': 39, 'OK': 40,\n",
    "'OR': 41, 'PA': 42, 'RI': 44, 'SC': 45, 'SD': 46, 'TN':47,\n",
    "'TX': 48, 'UT': 49, 'VT': 50, 'VA': 51,\n",
    "'WA': 53,'WV': 54, 'WI': 55, 'WY': 56, 'PR': 72}\n",
    "\n",
    "afinnfile = open(\"../Entrega/AFINN-111.txt\")\n",
    "afinnDict = {} # initialize an empty dictionary\n",
    "#scores_tuples = [line.decode('utf-8').split('\\t') for line in afinnline]\n",
    "#scores = dict((a,int(b)) for a,b in scores_tuples)\n",
    "\n",
    "for line in afinnfile:\n",
    "    term, score  = line.split(\"\\t\")  # The file is tab-delimited. \"\\t\" means \"tab character\"\n",
    "    afinnDict[term] = int(score)  # Convert the score to an integer.\n",
    "\n",
    "def getState(data):\n",
    "    if data[\"place\"] != None and data[\"place\"][\"country_code\"] == \"US\":\n",
    "        state = str(data[\"place\"][\"full_name\"]).lower().split(\", \")\n",
    "        \n",
    "        if len(state) > 1:\n",
    "            return state[1]\n",
    "\n",
    "def isState(state):\n",
    "    if state in states:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def det_sent(tweet): #helper method for determining net sentiment, will use the sentiment score to appply scores to unscored words.\n",
    "    terms_count = 0\n",
    "    score = 0\n",
    "\n",
    "    for word in tweet:\n",
    "        stripped_word = word.lower().strip().replace('.','').replace('?','').replace('!','')\n",
    "\n",
    "        if stripped_word in afinnDict.keys():\n",
    "            terms_count += 1\n",
    "            score += afinnDict[stripped_word]\n",
    "        \n",
    "    return terms_count, score\n",
    "\n",
    "def cleanNotUsefulTweets():\n",
    "    file = \"inp.txt\"\n",
    "    \n",
    "    linesToKeep = []\n",
    "    \n",
    "    with open(file, \"r\", encoding='utf-16') as ins:\n",
    "        \n",
    "        for line in ins:          \n",
    "            cleanline = line.strip(\"'<>() \").replace('\\'', '\\\"')\n",
    "            cleanline = cleanline.replace(\"b\\\"{\", \"{\")\n",
    "            cleanline = cleanline.replace(\"}\\\"\", \"}\")\n",
    "            cleanline = cleanline.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "        \n",
    "            if len(cleanline) > 1: ## to avoid empty lines \n",
    "                tweet = json.loads(cleanline, encoding=\"utf-16\")\n",
    "           \n",
    "                if \"created_at\" in tweet:\n",
    "                    state = getState(tweet)\n",
    "\n",
    "                    if isState(state):\n",
    "                        if \"text\" in tweet:                           \n",
    "                            tweetText = tweet[\"text\"]\n",
    "                            tokenizedTweet = nltk.word_tokenize(tweetText)\n",
    "                            \n",
    "                            score = 0\n",
    "                            numberTerms = 0\n",
    "                            \n",
    "                            numberTerms, score = det_sent(tokenizedTweet)\n",
    "                            \n",
    "                            if numberTerms > 0:\n",
    "                                linesToKeep.append(line)\n",
    "                                \n",
    "    with open(file, \"w\", encoding='utf-16') as ins:\n",
    "        for line in linesToKeep:\n",
    "            ins.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def isTweetInSapin(tweet):\n",
    "    return tweet[\"place\"] != None and tweet[\"place\"][\"country_code\"] == \"ES\"\n",
    "\n",
    "def cleanNotUsefulTweetsSpain():\n",
    "    file = \"inpSpain.txt\"\n",
    "\n",
    "    linesToKeep = []\n",
    "       \n",
    "    with open(file, \"r\", encoding='utf-16') as ins:\n",
    "        \n",
    "        for line in ins:          \n",
    "            cleanline = line.strip(\"'<>() \").replace('\\'', '\\\"')\n",
    "            cleanline = cleanline.replace(\"b\\\"{\", \"{\")\n",
    "            cleanline = cleanline.replace(\"}\\\"\", \"}\")\n",
    "            cleanline = cleanline.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "        \n",
    "            if len(cleanline) > 1: ## to avoid empty lines \n",
    "                tweet = json.loads(cleanline, encoding=\"utf-16\")\n",
    "           \n",
    "                if \"created_at\" in tweet:\n",
    "                    if isTweetInSapin(tweet):\n",
    "                        coordinates = tweet[\"place\"][\"bounding_box\"][\"coordinates\"][0][0]\n",
    "                        lang = tweet[\"lang\"]\n",
    "\n",
    "                        if coordinates != None and lang != None:\n",
    "                            linesToKeep.append(line)\n",
    "                            \n",
    "    with open(file, \"w\", encoding='utf-16') as ins:\n",
    "        for line in linesToKeep:\n",
    "            ins.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append(origFile, newFile):\n",
    "    origLines = []\n",
    "    newLines = []\n",
    "    \n",
    "    with open(origFile, \"r\", encoding='utf-16') as lines:\n",
    "        for line in lines:\n",
    "            origLines.append(line)\n",
    "\n",
    "    with open(newFile, \"r\", encoding='utf-16') as lines:\n",
    "        for line in lines:\n",
    "            if line not in origLines:\n",
    "                newLines.append(line)\n",
    "        \n",
    "    with open(origFile, \"w\", encoding='utf-16') as writer:\n",
    "        for line in origLines:\n",
    "            writer.write(line)\n",
    "            \n",
    "        for line in newLines:\n",
    "            writer.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanNotUsefulTweets()\n",
    "cleanNotUsefulTweetsSpain()\n",
    "\n",
    "append(\"../Entrega/inp.txt\", \"inp.txt\")\n",
    "append(\"../Entrega/inpSpain.txt\", \"inpSpain.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
