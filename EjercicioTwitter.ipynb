{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ejercicio de twitter.\n",
    "Entrega: 25-mar-2020 23:55\n",
    "\n",
    "Encontrar los 5 estados mÃ¡s felices de USA de acuerdo al anÃ¡lisis de sentimiento con AFFINN. \n",
    "\n",
    "Contenido. un fichero .ipynb con enunciado. Si no se hace completo indicad en un comentario lo que se ha conseguido Mostrar mapa USA con los estados coloreados por felicidad\n",
    "\n",
    "Realizar un mapa de EspaÃ±a que permita ver dÃ³nde se tuitea y en quÃ© idioma se tuitea\n",
    "\n",
    "Subir fichero ipynb y fichero html!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "states = [\"ak\",\"al\",\"ar\",\"az\",\"ca\",\"co\",\"ct\",\"de\",\"fl\",\"ga\",\"hi\",\"ia\",\"id\",\"il\",\n",
    "          \"in\",\"ks\",\"ky\",\"la\",\"ma\",\"md\",\"me\",\"mi\",\"mn\",\"mo\",\"ms\",\"mt\",\"nc\",\"nd\",\"ne\",\"nh\",\n",
    "          \"nj\",\"nm\",\"nv\",\"ny\",\"oh\",\"ok\",\"or\",\"pa\",\"ri\",\"sc\",\"sd\",\"tn\",\"tx\",\"ut\",\"va\",\"vt\",\n",
    "          \"wa\",\"wi\",\"wv\",\"wy\"]\n",
    "\n",
    "states_names = {'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois',\n",
    "'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n",
    "'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC':'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island',\n",
    "'SC': 'South Carolina', 'SD': 'South Dakota', 'TN':'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia',\n",
    "'WA': 'Washington','WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'}\n",
    "\n",
    "afinnfile = open(\"AFINN-111.txt\")\n",
    "afinnDict = {} # initialize an empty dictionary\n",
    "#scores_tuples = [line.decode('utf-8').split('\\t') for line in afinnline]\n",
    "#scores = dict((a,int(b)) for a,b in scores_tuples)\n",
    "\n",
    "for line in afinnfile:\n",
    "    term, score  = line.split(\"\\t\")  # The file is tab-delimited. \"\\t\" means \"tab character\"\n",
    "    afinnDict[term] = int(score)  # Convert the score to an integer.\n",
    "\n",
    "def getState(data):\n",
    "    if data[\"place\"] != None and data[\"place\"][\"country_code\"] == \"US\":\n",
    "        state = str(data[\"place\"][\"full_name\"]).lower().split(\", \")\n",
    "        \n",
    "        if len(state) > 1:\n",
    "            return state[1]\n",
    "\n",
    "def isState(state):\n",
    "    if state in states:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def det_sent(tweet): #helper method for determining net sentiment, will use the sentiment score to appply scores to unscored words.\n",
    "    terms_count = 0\n",
    "    score = 0\n",
    "\n",
    "    for word in tweet:\n",
    "        stripped_word = word.lower().strip().replace('.','').replace('?','').replace('!','')\n",
    "\n",
    "        if stripped_word in afinnDict.keys():\n",
    "            terms_count += 1\n",
    "            score += afinnDict[stripped_word]\n",
    "        \n",
    "    return terms_count, score\n",
    "\n",
    "def analyze():\n",
    "    file = \"output.txt\"\n",
    "    scored_tweets = []\n",
    "    tweetsByStates = {}\n",
    "    \n",
    "    with open(file, \"r\") as ins:\n",
    "        \n",
    "        for line in ins:          \n",
    "            \n",
    "            if len(line) > 1: ## to avoid empty lines \n",
    "                tweet = json.loads(line)\n",
    "           \n",
    "                if \"created_at\" in tweet:\n",
    "                    state = getState(tweet)\n",
    "\n",
    "                    if isState(state):\n",
    "                        if \"text\" in tweet:                           \n",
    "                            tweetText = tweet[\"text\"]\n",
    "                            tokenizedTweet = nltk.word_tokenize(tweetText)\n",
    "                            \n",
    "                            score = 0\n",
    "                            numberTerms = 0\n",
    "                            \n",
    "                            numberTerms, score = det_sent(tokenizedTweet)\n",
    "                            \n",
    "                            if numberTerms > 0:\n",
    "                                t = [tweetText, state, score, numberTerms]\n",
    "                                scored_tweets.append(t)\n",
    "                                \n",
    "                                if state in tweetsByStates:\n",
    "                                    tweetsByStates[state].append(score)\n",
    "                                else:\n",
    "                                    tweetsByStates[state] = [score]\n",
    "\"\"\"                         \n",
    "    for [tweetText, state, score, numberTerms] in scored_tweets:\n",
    "        print(\"Tweet: \" + tweetText)\n",
    "        print(\"State: \" + state)\n",
    "        print(\"Score: \" + str(score))\n",
    "        print(\"NÂº tÃ©rminos analizados: \" + str(numberTerms))\n",
    "        print(\"----------------------\")\n",
    "\"\"\"\n",
    "\n",
    "    print(tweetsByStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Setting here on break talking to my Sister about the orangutan that flipped me off at the Zoo last Summer lol. It was funny\n",
      "State: in\n",
      "Score: 7\n",
      "NÂº tÃ©rminos analizados: 2\n",
      "----------------------\n",
      "Tweet: ğŸ„ğŸ…ğŸâ›„\n",
      "Luke Hemmings from @5SOS\n",
      "who is Santa's \n",
      "favorite singer?\n",
      "Elf-is Presley! \n",
      "I love you!â¤ğŸ’š\n",
      "follow me please?\n",
      "@Luke5SOS\n",
      "ğŸ„ğŸ…ğŸâ›„\n",
      "17,908\n",
      "State: mi\n",
      "Score: 6\n",
      "NÂº tÃ©rminos analizados: 3\n",
      "----------------------\n",
      "Tweet: @brittany_vv she won't let me hand mine in lmao\n",
      "State: ri\n",
      "Score: 4\n",
      "NÂº tÃ©rminos analizados: 1\n",
      "----------------------\n",
      "Tweet: â€œ@trayXO_: College is 30x better than high school. I don't see how people say they miss it.â€ Fuck high school\n",
      "State: nj\n",
      "Score: -4\n",
      "NÂº tÃ©rminos analizados: 3\n",
      "----------------------\n",
      "Tweet: @Mondeezzy38 good &amp; nah\n",
      "State: ca\n",
      "Score: 3\n",
      "NÂº tÃ©rminos analizados: 1\n",
      "----------------------\n",
      "Tweet: Daniels getting butt hurt.\n",
      "State: tx\n",
      "Score: -2\n",
      "NÂº tÃ©rminos analizados: 1\n",
      "----------------------\n",
      "{'in': [7], 'mi': [6], 'ri': [4], 'nj': [-4], 'ca': [3], 'tx': [-2]}\n"
     ]
    }
   ],
   "source": [
    "analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
