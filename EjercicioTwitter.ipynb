{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ejercicio de twitter.\n",
    "Entrega: 25-mar-2020 23:55\n",
    "\n",
    "Encontrar los 5 estados más felices de USA de acuerdo al análisis de sentimiento con AFFINN. \n",
    "\n",
    "Contenido. un fichero .ipynb con enunciado. Si no se hace completo indicad en un comentario lo que se ha conseguido Mostrar mapa USA con los estados coloreados por felicidad\n",
    "\n",
    "Realizar un mapa de España que permita ver dónde se tuitea y en qué idioma se tuitea\n",
    "\n",
    "Subir fichero ipynb y fichero html!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "states = [\"ak\",\"al\",\"ar\",\"az\",\"ca\",\"co\",\"ct\",\"de\",\"fl\",\"ga\",\"hi\",\"ia\",\"id\",\"il\",\n",
    "          \"in\",\"ks\",\"ky\",\"la\",\"ma\",\"md\",\"me\",\"mi\",\"mn\",\"mo\",\"ms\",\"mt\",\"nc\",\"nd\",\"ne\",\"nh\",\n",
    "          \"nj\",\"nm\",\"nv\",\"ny\",\"oh\",\"ok\",\"or\",\"pa\",\"ri\",\"sc\",\"sd\",\"tn\",\"tx\",\"ut\",\"va\",\"vt\",\n",
    "          \"wa\",\"wi\",\"wv\",\"wy\"]\n",
    "\n",
    "states_names = {'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "'CT': 'Connecticut', 'DE': 'Delaware', 'DC': 'District of Columbia', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois',\n",
    "'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n",
    "'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC':'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island',\n",
    "'SC': 'South Carolina', 'SD': 'South Dakota', 'TN':'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia',\n",
    "'WA': 'Washington','WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming', 'PR': 'Puerto Rico'}\n",
    "\n",
    "afinnfile = open(\"AFINN-111.txt\")\n",
    "afinnDict = {} # initialize an empty dictionary\n",
    "#scores_tuples = [line.decode('utf-8').split('\\t') for line in afinnline]\n",
    "#scores = dict((a,int(b)) for a,b in scores_tuples)\n",
    "\n",
    "for line in afinnfile:\n",
    "    term, score  = line.split(\"\\t\")  # The file is tab-delimited. \"\\t\" means \"tab character\"\n",
    "    afinnDict[term] = int(score)  # Convert the score to an integer.\n",
    "\n",
    "def getState(data):\n",
    "    if data[\"place\"] != None and data[\"place\"][\"country_code\"] == \"US\":\n",
    "        state = str(data[\"place\"][\"full_name\"]).lower().split(\", \")\n",
    "        \n",
    "        if len(state) > 1:\n",
    "            return state[1]\n",
    "\n",
    "def isState(state):\n",
    "    if state in states:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def det_sent(tweet): #helper method for determining net sentiment, will use the sentiment score to appply scores to unscored words.\n",
    "    terms_count = 0\n",
    "    score = 0\n",
    "\n",
    "    for word in tweet:\n",
    "        stripped_word = word.lower().strip().replace('.','').replace('?','').replace('!','')\n",
    "\n",
    "        if stripped_word in afinnDict.keys():\n",
    "            terms_count += 1\n",
    "            score += afinnDict[stripped_word]\n",
    "        \n",
    "    return terms_count, score\n",
    "\n",
    "def analyze():\n",
    "    file = \"inp.txt\"\n",
    "    scored_tweets = []\n",
    "    tweetsByStates = {}\n",
    "       \n",
    "    with open(file, \"r\", encoding='utf-16') as ins:\n",
    "        \n",
    "        for line in ins:          \n",
    "            line = line.strip(\"'<>() \").replace('\\'', '\\\"')\n",
    "            line = line.replace(\"b\\\"{\", \"{\")\n",
    "            line = line.replace(\"}\\\"\", \"}\")\n",
    "            line = line.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "        \n",
    "            if len(line) > 1: ## to avoid empty lines \n",
    "                tweet = json.loads(line, encoding=\"utf-16\")\n",
    "           \n",
    "                if \"created_at\" in tweet:\n",
    "                    state = getState(tweet)\n",
    "\n",
    "                    if isState(state):\n",
    "                        if \"text\" in tweet:                           \n",
    "                            tweetText = tweet[\"text\"]\n",
    "                            tokenizedTweet = nltk.word_tokenize(tweetText)\n",
    "                            \n",
    "                            score = 0\n",
    "                            numberTerms = 0\n",
    "                            \n",
    "                            numberTerms, score = det_sent(tokenizedTweet)\n",
    "                            \n",
    "                            if numberTerms > 0:\n",
    "                                t = [tweetText, state, score, numberTerms]\n",
    "                                scored_tweets.append(t)\n",
    "                                \n",
    "                                if state in tweetsByStates:\n",
    "                                    tweetsByStates[state].append(score)\n",
    "                                else:\n",
    "                                    tweetsByStates[state] = [score]\n",
    "    print(tweetsByStates)\n",
    "    \n",
    "    with open('out.csv', mode='w',  newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"state\", \"id\", \"meanSent\"])\n",
    "        i = 0\n",
    "        mean = None\n",
    "        for state in states_names:\n",
    "            i+=1\n",
    "            lowerCaseState = state.lower()\n",
    "            if lowerCaseState in tweetsByStates:\n",
    "                mean = sum(tweetsByStates[lowerCaseState])/len(tweetsByStates[lowerCaseState])\n",
    "            else: mean = 0\n",
    "            \n",
    "            writer.writerow([states_names[state], i, mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ca': [2, 2, 3], 'tx': [6, 7, -6, -3, -1, 2], 'al': [1], 'oh': [-10, 2, 3, 1, 0, -3], 'id': [2], 'ga': [-5, -4, -4], 'or': [2], 'fl': [1, -3, 3], 'ny': [3, -2, 3, -4], 'mn': [1, -5, 1], 'pa': [3], 'nj': [2], 'mi': [-2], 'nd': [-3], 'ok': [4], 'md': [1]}\n"
     ]
    }
   ],
   "source": [
    "analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-49-469586974c90>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-469586974c90>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    print(sys.exc_info())\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import sys, json\n",
    "struct = {}\n",
    "try:\n",
    "    try: #try parsing to dict\n",
    "        dataform = str(response_json).strip(\"'<>() \").replace('\\'', '\\\"')\n",
    "        struct = json.loads(dataform)\n",
    "    except:\n",
    "        print(repr(resonse_json))\n",
    "        print(sys.exc_info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
