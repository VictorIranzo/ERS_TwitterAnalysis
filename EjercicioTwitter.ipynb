{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ejercicio de twitter.\n",
    "Entrega: 25-mar-2020 23:55\n",
    "\n",
    "Encontrar los 5 estados más felices de USA de acuerdo al análisis de sentimiento con AFFINN. \n",
    "\n",
    "Contenido. un fichero .ipynb con enunciado. Si no se hace completo indicad en un comentario lo que se ha conseguido Mostrar mapa USA con los estados coloreados por felicidad\n",
    "\n",
    "Realizar un mapa de España que permita ver dónde se tuitea y en qué idioma se tuitea\n",
    "\n",
    "Subir fichero ipynb y fichero html!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "states = [\"ak\",\"al\",\"ar\",\"az\",\"ca\",\"co\",\"ct\",\"de\",\"fl\",\"ga\",\"hi\",\"ia\",\"id\",\"il\",\n",
    "          \"in\",\"ks\",\"ky\",\"la\",\"ma\",\"md\",\"me\",\"mi\",\"mn\",\"mo\",\"ms\",\"mt\",\"nc\",\"nd\",\"ne\",\"nh\",\n",
    "          \"nj\",\"nm\",\"nv\",\"ny\",\"oh\",\"ok\",\"or\",\"pa\",\"ri\",\"sc\",\"sd\",\"tn\",\"tx\",\"ut\",\"va\",\"vt\",\n",
    "          \"wa\",\"wi\",\"wv\",\"wy\"]\n",
    "\n",
    "states_names = {'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado',\n",
    "'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois',\n",
    "'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n",
    "'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC':'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island',\n",
    "'SC': 'South Carolina', 'SD': 'South Dakota', 'TN':'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia',\n",
    "'WA': 'Washington','WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'}\n",
    "\n",
    "afinnfile = open(\"AFINN-111.txt\")\n",
    "afinnDict = {} # initialize an empty dictionary\n",
    "#scores_tuples = [line.decode('utf-8').split('\\t') for line in afinnline]\n",
    "#scores = dict((a,int(b)) for a,b in scores_tuples)\n",
    "\n",
    "for line in afinnfile:\n",
    "    term, score  = line.split(\"\\t\")  # The file is tab-delimited. \"\\t\" means \"tab character\"\n",
    "    afinnDict[term] = int(score)  # Convert the score to an integer.\n",
    "\n",
    "def getState(data):\n",
    "    if data[\"place\"] != None and data[\"place\"][\"country_code\"] == \"US\":\n",
    "        state = str(data[\"place\"][\"full_name\"]).lower().split(\", \")\n",
    "        \n",
    "        if len(state) > 1:\n",
    "            return state[1]\n",
    "\n",
    "def isState(state):\n",
    "    if state in states:\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def det_sent(tweet): #helper method for determining net sentiment, will use the sentiment score to appply scores to unscored words.\n",
    "    terms_count = 0\n",
    "    score = 0\n",
    "\n",
    "    for word in tweet:\n",
    "        stripped_word = word.lower().strip().replace('.','').replace('?','').replace('!','')\n",
    "\n",
    "        if stripped_word in afinnDict.keys():\n",
    "            terms_count += 1\n",
    "            score += afinnDict[stripped_word]\n",
    "        \n",
    "    return terms_count, score\n",
    "\n",
    "def analyze():\n",
    "    file = \"output.txt\"\n",
    "    scored_tweets = []\n",
    "    tweetsByStates = {}\n",
    "    \n",
    "    with open(file, \"r\") as ins:\n",
    "        \n",
    "        for line in ins:          \n",
    "            \n",
    "            if len(line) > 1: ## to avoid empty lines \n",
    "                tweet = json.loads(line)\n",
    "           \n",
    "                if \"created_at\" in tweet:\n",
    "                    state = getState(tweet)\n",
    "\n",
    "                    if isState(state):\n",
    "                        if \"text\" in tweet:                           \n",
    "                            tweetText = tweet[\"text\"]\n",
    "                            tokenizedTweet = nltk.word_tokenize(tweetText)\n",
    "                            \n",
    "                            score = 0\n",
    "                            numberTerms = 0\n",
    "                            \n",
    "                            numberTerms, score = det_sent(tokenizedTweet)\n",
    "                            \n",
    "                            if numberTerms > 0:\n",
    "                                t = [tweetText, state, score, numberTerms]\n",
    "                                scored_tweets.append(t)\n",
    "                                \n",
    "                                if state in tweetsByStates:\n",
    "                                    tweetsByStates[state].append(score)\n",
    "                                else:\n",
    "                                    tweetsByStates[state] = [score]\n",
    "\"\"\"                         \n",
    "    for [tweetText, state, score, numberTerms] in scored_tweets:\n",
    "        print(\"Tweet: \" + tweetText)\n",
    "        print(\"State: \" + state)\n",
    "        print(\"Score: \" + str(score))\n",
    "        print(\"Nº términos analizados: \" + str(numberTerms))\n",
    "        print(\"----------------------\")\n",
    "\"\"\"\n",
    "\n",
    "    print(tweetsByStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Setting here on break talking to my Sister about the orangutan that flipped me off at the Zoo last Summer lol. It was funny\n",
      "State: in\n",
      "Score: 7\n",
      "Nº términos analizados: 2\n",
      "----------------------\n",
      "Tweet: 🎄🎅🎁⛄\n",
      "Luke Hemmings from @5SOS\n",
      "who is Santa's \n",
      "favorite singer?\n",
      "Elf-is Presley! \n",
      "I love you!❤💚\n",
      "follow me please?\n",
      "@Luke5SOS\n",
      "🎄🎅🎁⛄\n",
      "17,908\n",
      "State: mi\n",
      "Score: 6\n",
      "Nº términos analizados: 3\n",
      "----------------------\n",
      "Tweet: @brittany_vv she won't let me hand mine in lmao\n",
      "State: ri\n",
      "Score: 4\n",
      "Nº términos analizados: 1\n",
      "----------------------\n",
      "Tweet: “@trayXO_: College is 30x better than high school. I don't see how people say they miss it.” Fuck high school\n",
      "State: nj\n",
      "Score: -4\n",
      "Nº términos analizados: 3\n",
      "----------------------\n",
      "Tweet: @Mondeezzy38 good &amp; nah\n",
      "State: ca\n",
      "Score: 3\n",
      "Nº términos analizados: 1\n",
      "----------------------\n",
      "Tweet: Daniels getting butt hurt.\n",
      "State: tx\n",
      "Score: -2\n",
      "Nº términos analizados: 1\n",
      "----------------------\n",
      "{'in': [7], 'mi': [6], 'ri': [4], 'nj': [-4], 'ca': [3], 'tx': [-2]}\n"
     ]
    }
   ],
   "source": [
    "analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
